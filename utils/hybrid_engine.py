import os
import asyncio
import logging
import httpx


logger = logging.getLogger(__name__)


class HybridGrokkyEngine:
    def __init__(self):
        self.openai_key = os.getenv("OPENAI_API_KEY")
        self.xai_key = os.getenv("XAI_API_KEY")
        self.openai_h = {
            "Authorization": f"Bearer {self.openai_key}",
            "Content-Type": "application/json",
            "OpenAI-Beta": "assistants=v1"
        }
        self.xai_h = {
            "Authorization": f"Bearer {self.xai_key}",
            "Content-Type": "application/json"
        }
        self.threads = {}  # user_id -> thread_id (None if creation failed)
        # ID –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ —Å–æ–∑–¥–∞–Ω–Ω–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ OpenAI
        self.ASSISTANT_ID = os.getenv("OPENAI_ASSISTANT_ID")

    async def setup_openai_infrastructure(self):
        """Dummy check to ensure OpenAI credentials are configured."""
        if not self.openai_key:
            raise RuntimeError("OPENAI_API_KEY is not configured")
        # Nothing else to set up for now
        return True

    async def get_or_create_thread(self, user_id: str):
        """–ü–æ–ª—É—á–∞–µ—Ç –∏–ª–∏ —Å–æ–∑–¥–∞–µ—Ç Thread –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

        –ï—Å–ª–∏ –∫–ª—é—á OpenAI –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω –∏–ª–∏ –∑–∞–ø—Ä–æ—Å –∑–∞–≤–µ—Ä—à–∏–ª—Å—è –æ—à–∏–±–∫–æ–π, –º–µ—Ç–æ–¥
        –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç ``None`` –∏ –ø–∞–º—è—Ç—å —á–µ—Ä–µ–∑ OpenAI –æ—Ç–∫–ª—é—á–∞–µ—Ç—Å—è.  –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç
        –ì—Ä–æ–∫–∫–∏ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Ä–∞–±–æ—Ç—É —Ç–æ–ª—å–∫–æ –Ω–∞ Grok‚Äë3 –±–µ–∑ –ø–∞–¥–µ–Ω–∏—è –≤—Å–µ–≥–æ —Å–µ—Ä–≤–∏—Å–∞.
        """

        if not self.openai_key:
            # –ü–∞–º—è—Ç—å —á–µ—Ä–µ–∑ OpenAI –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
            return None

        if user_id not in self.threads:
            try:
                async with httpx.AsyncClient() as client:
                    res = await client.post(
                        "https://api.openai.com/v1/threads",
                        headers=self.openai_h,
                        json={"metadata": {"user_id": user_id}},
                        timeout=15,
                    )
                    res.raise_for_status()
                    self.threads[user_id] = res.json().get("id")
            except Exception as exc:  # pragma: no cover - network
                self.threads[user_id] = None
                logger.error("OpenAI thread creation failed: %s", exc, exc_info=True)
        return self.threads.get(user_id)

    async def add_memory(self, user_id: str, content: str, role="user"):
        """–î–æ–±–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ Thread –ø–∞–º—è—Ç–∏"""
        tid = await self.get_or_create_thread(user_id)
        if not tid:
            return
        async with httpx.AsyncClient() as client:
            try:
                await client.post(
                    f"https://api.openai.com/v1/threads/{tid}/messages",
                    headers=self.openai_h,
                    json={"role": role, "content": content},
                    timeout=15,
                )
            except Exception as exc:  # pragma: no cover - network
                logger.warning("OpenAI add_memory failed: %s", exc, exc_info=True)

    async def search_memory(self, user_id: str, query: str, limit: int = 5) -> str:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ –≤ –ø–∞–º—è—Ç–∏ —á–µ—Ä–µ–∑ GPT-4o mini Assistant.

        –ü–∞—Ä–∞–º–µ—Ç—Ä ``limit`` –¥–æ–±–∞–≤–ª–µ–Ω –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å ``VectorGrokkyEngine``
        –∏ —É–ø—Ä–∞–≤–ª—è–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Å–æ–æ–±—â–µ–Ω–∏–π, –∏–∑–≤–ª–µ–∫–∞–µ–º—ã—Ö –∏–∑ –ø–æ—Ç–æ–∫–∞. –í —Ç–µ–∫—É—â–µ–π
        —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è —á–∏—Å–ª–∞ –ø–æ–ª—É—á–∞–µ–º—ã—Ö
        —Å–æ–æ–±—â–µ–Ω–∏–π –∏ –Ω–µ –≤–ª–∏—è–µ—Ç –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ–∏—Å–∫–∞.
        """
        if not (self.ASSISTANT_ID and self.openai_key):
            return ""

        tid = await self.get_or_create_thread(user_id)
        if not tid:
            return ""

        async with httpx.AsyncClient() as client:
            try:
                # –¥–æ–±–∞–≤–ª—è–µ–º –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
                await client.post(
                    f"https://api.openai.com/v1/threads/{tid}/messages",
                    headers=self.openai_h,
                    json={"role": "user", "content": f"–ü–û–ò–°–ö: {query}"},
                    timeout=15,
                )

                # –∑–∞–ø—É—Å–∫–∞–µ–º Assistant
                run = await client.post(
                    f"https://api.openai.com/v1/threads/{tid}/runs",
                    headers=self.openai_h,
                    json={"assistant_id": self.ASSISTANT_ID},
                    timeout=15,
                )
                run_id = run.json()["id"]

                # –∂–¥—ë–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
                while True:
                    await asyncio.sleep(1)
                    st = await client.get(
                        f"https://api.openai.com/v1/threads/{tid}/runs/{run_id}",
                        headers=self.openai_h,
                        timeout=15,
                    )
                    if st.json().get("status") == "completed":
                        break

                # –±–µ—Ä—ë–º –æ—Ç–≤–µ—Ç
                msgs = await client.get(
                    f"https://api.openai.com/v1/threads/{tid}/messages",
                    headers=self.openai_h,
                    params={"limit": limit},
                    timeout=15,
                )
                data = msgs.json().get("data", [])
                if data:
                    return data[0]["content"][0]["text"]["value"]
            except Exception as exc:  # pragma: no cover - network
                logger.error("OpenAI search_memory failed: %s", exc, exc_info=True)
        return ""

    async def get_recent_memory(self, user_id: str, limit: int = 10) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ –ø–∞–º—è—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
        if not (self.ASSISTANT_ID and self.openai_key):
            return ""

        tid = await self.get_or_create_thread(user_id)
        if not tid:
            return ""

        async with httpx.AsyncClient() as client:
            try:
                msgs = await client.get(
                    f"https://api.openai.com/v1/threads/{tid}/messages",
                    headers=self.openai_h,
                    params={"limit": limit},
                    timeout=15,
                )
                data = msgs.json().get("data", [])
                context_parts = []
                for msg in reversed(data):  # chronological order
                    role = msg.get("role", "")
                    content = msg.get("content", [])
                    if content:
                        text = content[0].get("text", {}).get("value", "")
                        if text:
                            context_parts.append(f"[{role}]: {text}")
                if context_parts:
                    return "\n".join(context_parts)
            except Exception as exc:  # pragma: no cover - network
                logger.warning("OpenAI get_recent_memory failed: %s", exc, exc_info=True)
        return ""

    async def _safe_xai_call(self, payload: dict, retries: int = 3) -> str:
        """Safely call the xAI API with retries and error handling."""
        for attempt in range(retries):
            try:
                async with httpx.AsyncClient() as client:
                    res = await client.post(
                        "https://api.x.ai/v1/chat/completions",
                        headers=self.xai_h,
                        json=payload,
                    )
                    res.raise_for_status()
                    return res.json()["choices"][0]["message"]["content"]
            except httpx.TimeoutException:
                logger.warning("xAI timeout, retrying (%d/%d)", attempt + 1, retries)
                await asyncio.sleep(2 ** attempt)
            except httpx.HTTPStatusError as e:
                if "stop" in e.response.text.lower():
                    payload.pop("stop", None)
                    logger.warning("Removed unsupported 'stop' parameter and retrying")
                    continue
                logger.error("HTTP error from xAI: %s", e)
                break
            except Exception as e:
                logger.error("Unexpected xAI error: %s", e)
                break
        from utils.prompt import get_chaos_response
        return f"üåÄ Grokky glitch! {get_chaos_response()}"

    async def generate_with_xai(
        self, messages: list, context: str = ""
    ) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç —Å –ø–æ–º–æ—â—å—é xAI Grok-3"""
        from utils.prompt import build_system_prompt

        system = build_system_prompt()
        if context:
            system += f"\n\n–ö–û–ù–¢–ï–ö–°–¢ –ò–ó –ü–ê–ú–Ø–¢–ò:\n{context}"

        payload = {
            "model": "grok-3",
            "messages": [{"role": "system", "content": system}, *messages],
            "temperature": 1.0  # slightly higher temperature for Grok-3
        }

        return await self._safe_xai_call(payload)
