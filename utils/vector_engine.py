import os
import asyncio
import httpx
import json
import traceback
import logging
import time
from datetime import datetime
import hashlib
import numpy as np

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞
logger = logging.getLogger(__name__)


class VectorGrokkyEngine:
    def __init__(self):
        self.xai_key = os.getenv("XAI_API_KEY")
        self.xai_h = {
            "Authorization": f"Bearer {self.xai_key}",
            "Content-Type": "application/json",
        }

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Pinecone
        self.pinecone_api_key = os.getenv("PINECONE_API_KEY")
        self.pinecone_index = os.getenv("PINECONE_INDEX")
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è —É–∫–∞–∑–∞–Ω–∏—è –æ–±–ª–∞–∫–∞ –∏ —Ä–µ–≥–∏–æ–Ω–∞ Pinecone
        self.pinecone_environment = os.getenv("PINECONE_ENVIRONMENT", "us-west1-gcp")
        self.vector_dimension = 1536  # –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–∞, —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –¥–ª—è OpenAI
        self.pc = None
        self.index = None

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Pinecone
        if self.pinecone_api_key and self.pinecone_index:
            self._init_pinecone()
        else:
            logger.warning("Pinecone –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω, —Ñ—É–Ω–∫—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ø–∞–º—è—Ç–∏ –æ—Ç–∫–ª—é—á–µ–Ω–∞")

        # –°–Ω–µ–ø—à–æ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
        self._create_memory_snapshot()

    def _init_pinecone(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å Pinecone"""
        try:
            from pinecone import Pinecone, ServerlessSpec

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–≥–∏–æ–Ω –∏ –æ–±–ª–∞–∫–æ –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è
            if "-" in self.pinecone_environment:
                region, cloud = self.pinecone_environment.split("-", 1)
            else:
                region, cloud = self.pinecone_environment, "aws"

            self.pc = Pinecone(api_key=self.pinecone_api_key)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞
            existing_indexes = self.pc.list_indexes().names()

            if self.pinecone_index not in existing_indexes:
                logger.info(f"–°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –∏–Ω–¥–µ–∫—Å Pinecone: {self.pinecone_index}")
                self.pc.create_index(
                    name=self.pinecone_index,
                    dimension=self.vector_dimension,
                    metric="cosine",
                    spec=ServerlessSpec(cloud=cloud, region=region),
                )
                # –î–∞–µ–º –≤—Ä–µ–º—è –Ω–∞ —Å–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞
                time.sleep(1)

            self.index = self.pc.Index(self.pinecone_index)
            logger.info(f"Pinecone –∏–Ω–¥–µ–∫—Å '{self.pinecone_index}' –ø–æ–¥–∫–ª—é—á–µ–Ω —É—Å–ø–µ—à–Ω–æ")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–Ω–¥–µ–∫—Å–∞
            stats = self.index.describe_index_stats()
            logger.info(f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–Ω–¥–µ–∫—Å–∞: {stats}")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Pinecone: {e}")
            logger.error(traceback.format_exc())
            self.index = None

    def _create_memory_snapshot(self):
        """–°–æ–∑–¥–∞–µ—Ç —Å–Ω–µ–ø—à–æ—Ç —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–∞–º—è—Ç–∏ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ"""
        if not self.index:
            logger.warning("–°–Ω–µ–ø—à–æ—Ç –ø–∞–º—è—Ç–∏ –Ω–µ —Å–æ–∑–¥–∞–Ω - Pinecone –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω")
            return

        try:
            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–Ω–¥–µ–∫—Å–∞
            stats = self.index.describe_index_stats()
            total_vectors = stats.get("total_vector_count", 0)

            logger.info(f"====== –°–ù–ï–ü–®–û–¢ –ü–ê–ú–Ø–¢–ò ======")
            logger.info(f"–í—Ä–µ–º—è: {datetime.now().isoformat()}")
            logger.info(f"–í—Å–µ–≥–æ –≤–µ–∫—Ç–æ—Ä–æ–≤ –≤ –±–∞–∑–µ: {total_vectors}")

            # –ü–æ–ª—É—á–∞–µ–º –æ–±—Ä–∞–∑–µ—Ü –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ (–¥–æ 5 –∑–∞–ø–∏—Å–µ–π)
            if total_vectors > 0:
                try:
                    # Fetching sample of vectors with their metadata
                    # This is a simple approach - in production we'd use proper querying
                    sample_records = []
                    # This is pseudocode as Pinecone doesn't have a direct "list all" function
                    # In a real implementation, you would use a proper query approach

                    logger.info("–û–±—Ä–∞–∑–µ—Ü –∑–∞–ø–∏—Å–µ–π –≤ –ø–∞–º—è—Ç–∏:")
                    for i, record in enumerate(sample_records[:5]):
                        metadata = record.get("metadata", {})
                        logger.info(
                            f"  {i+1}. User: {metadata.get('user_id')}, Role: {metadata.get('role')}"
                        )
                        logger.info(f"     Content: {metadata.get('text', '')[:50]}...")

                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –æ–±—Ä–∞–∑—Ü–∞ –¥–∞–Ω–Ω—ã—Ö: {e}")

            logger.info(f"============================")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Å–Ω–µ–ø—à–æ—Ç–∞ –ø–∞–º—è—Ç–∏: {e}")
            logger.error(traceback.format_exc())

    async def generate_embedding(self, text):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω—ã–π —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è —Ç–µ–∫—Å—Ç–∞"""
        # –í –∏–¥–µ–∞–ª–µ –∑–¥–µ—Å—å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤—ã–∑–æ–≤ –º–æ–¥–µ–ª–∏ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
        # –ü–æ–∫–∞ —Ä–µ–∞–ª–∏–∑—É–µ–º —á–µ—Ä–µ–∑ —Ö–µ—à-—Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –¥–µ–º–æ

        # –°–æ–∑–¥–∞–µ–º –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ö–µ—à —Ç–µ–∫—Å—Ç–∞
        hash_obj = hashlib.sha256(text.encode())
        hash_digest = hash_obj.digest()

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Å–µ–≤–¥–æ-–≤–µ–∫—Ç–æ—Ä –Ω—É–∂–Ω–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
        vector = []
        for i in range(self.vector_dimension):
            byte_index = i % len(hash_digest)
            vector.append(
                (hash_digest[byte_index] / 255.0) * 2 - 1
            )  # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ [-1, 1]

        return vector

    async def add_memory(self, user_id: str, content: str, role="user"):
        """–î–æ–±–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ø–∞–º—è—Ç—å"""
        if not self.index:
            return True  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º, –µ—Å–ª–∏ Pinecone –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω

        try:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è —Ç–µ–∫—Å—Ç–∞
            embedding = await self.generate_embedding(content)

            # –°–æ–∑–¥–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            metadata = {
                "text": content[:1000],  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É —Ç–µ–∫—Å—Ç–∞
                "role": role,
                "user_id": user_id,
                "timestamp": datetime.now().isoformat(),
            }

            # –£–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –¥–ª—è –∑–∞–ø–∏—Å–∏
            record_id = f"{user_id}_{role}_{int(time.time()*1000)}"

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Pinecone
            self.index.upsert(vectors=[(record_id, embedding, metadata)])

            logger.info(
                f"–î–æ–±–∞–≤–ª–µ–Ω–∞ –∑–∞–ø–∏—Å—å –≤ –ø–∞–º—è—Ç—å: user={user_id}, role={role}, id={record_id}"
            )
            return True

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤ –ø–∞–º—è—Ç—å: {e}")
            logger.error(traceback.format_exc())
            return False

    async def search_memory(self, user_id: str, query: str, limit=5) -> str:
        """–ò—â–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤ –ø–∞–º—è—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–ª–∏–∑–æ—Å—Ç–∏"""
        if not self.index:
            return ""  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç, –µ—Å–ª–∏ Pinecone –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω

        try:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
            query_embedding = await self.generate_embedding(query)

            # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ –∑–∞–ø–∏—Å–∏ –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            results = self.index.query(
                vector=query_embedding,
                filter={"user_id": user_id},
                top_k=limit,
                include_metadata=True,
            )

            # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
            context_parts = []

            for match in results.get("matches", []):
                metadata = match.get("metadata", {})
                score = match.get("score", 0)

                if score < 0.7:  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –∑–∞–ø–∏—Å–∏ —Å –Ω–∏–∑–∫–æ–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å—é
                    continue

                text = metadata.get("text", "")
                role = metadata.get("role", "")
                timestamp = metadata.get("timestamp", "")

                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∑–∞–ø–∏—Å—å –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                context_parts.append(f"[{role} @ {timestamp}]: {text}")

            # –°–æ–±–∏—Ä–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
            if context_parts:
                context = "\n\n".join(context_parts)
                logger.info(f"–ù–∞–π–¥–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤ –ø–∞–º—è—Ç–∏: {len(context_parts)} –∑–∞–ø–∏—Å–µ–π")
                return context
            else:
                logger.info("–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤ –ø–∞–º—è—Ç–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω")
                return ""

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –≤ –ø–∞–º—è—Ç–∏: {e}")
            logger.error(traceback.format_exc())
            return ""

    async def generate_with_xai(self, messages: list, context: str = "") -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç —Å –ø–æ–º–æ—â—å—é xAI Grok-3"""
        from utils.prompt import build_system_prompt

        system = build_system_prompt()
        if context:
            system += f"\n\n–ö–û–ù–¢–ï–ö–°–¢ –ò–ó –ü–ê–ú–Ø–¢–ò:\n{context}"

        payload = {
            "model": "grok-3",
            "messages": [{"role": "system", "content": system}, *messages],
            "temperature": 1.0,  # slightly higher temperature for more creativity
        }

        async with httpx.AsyncClient() as client:
            try:
                res = await client.post(
                    "https://api.x.ai/v1/chat/completions",
                    headers=self.xai_h,
                    json=payload,
                    timeout=30.0,
                )
                res.raise_for_status()
                return res.json()["choices"][0]["message"]["content"]
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å xAI: {e}")
                logger.error(traceback.format_exc())
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—ã–π –æ—Ç–≤–µ—Ç –ø—Ä–∏ –æ—à–∏–±–∫–µ
                return "üåÄ –ì—Ä–æ–∫–∫–∏ –≤ –∑–∞–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–µ! –≠–ª–µ–∫—Ç—Ä–∏—á–µ—Å–∫–∏–µ –∏–º–ø—É–ª—å—Å—ã –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω—ã. –ü–æ–ø—Ä–æ–±—É–π –µ—â–µ —Ä–∞–∑!"

    async def get_recent_memory(self, user_id: str, limit: int = 10) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
        if not self.index:
            return ""

        try:
            zero_vec = [0.0] * self.vector_dimension
            results = self.index.query(
                vector=zero_vec,
                filter={"user_id": user_id},
                top_k=limit,
                include_metadata=True,
            )

            records = sorted(
                results.get("matches", []),
                key=lambda x: x.get("metadata", {}).get("timestamp", ""),
                reverse=True,
            )
            texts = [r.get("metadata", {}).get("text", "") for r in records]
            return "\n".join(texts)

        except Exception as e:
            logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –∑–∞–ø–∏—Å–µ–π: %s", e)
            logger.error(traceback.format_exc())
            return ""
