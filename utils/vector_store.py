import os
import glob
import json
import hashlib
import asyncio
import requests
from pinecone import Pinecone, PineconeException
import openai
from datetime import datetime, timedelta
import random  # –î–æ–±–∞–≤–ª–µ–Ω –∏–º–ø–æ—Ä—Ç
from utils.telegram_utils import send_telegram_message

VECTOR_META_PATH = "vector_store.meta.json"
EMBED_DIM = 1536  # –î–ª—è OpenAI ada-002
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
PINECONE_INDEX = os.getenv("PINECONE_INDEX")
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
SNAPSHOT_LOG_PATH = "data/snapshot_log.json"

pc = Pinecone(api_key=PINECONE_API_KEY)
if PINECONE_INDEX not in [x["name"] for x in pc.list_indexes()]:
    pc.create_index(name=PINECONE_INDEX, dimension=EMBED_DIM, metric="cosine")

vector_index = pc.Index(PINECONE_INDEX)

def file_hash(fname):
    with open(fname, "rb") as f:
        return hashlib.md5(f.read()).hexdigest()

def scan_files(path="config/*.md"):
    files = {}
    for fname in glob.glob(path):
        files[fname] = file_hash(fname)
    return files

def load_vector_meta():
    if os.path.isfile(VECTOR_META_PATH):
        with open(VECTOR_META_PATH, "r") as f:
            return json.load(f)
    return {}

def save_vector_meta(meta):
    with open(VECTOR_META_PATH, "w") as f:
        json.dump(meta, f)

def load_snapshot_log():
    if os.path.isfile(SNAPSHOT_LOG_PATH):
        with open(SNAPSHOT_LOG_PATH, "r") as f:
            return json.load(f)
    return []

def save_snapshot_log(log):
    with open(SNAPSHOT_LOG_PATH, "w") as f:
        json.dump(log, f, ensure_ascii=False, indent=2)

async def get_embedding(text, openai_api_key):
    openai.api_key = openai_api_key
    try:
        res = openai.embeddings.create(
            model="text-embedding-ada-002",
            input=text
        )
        return res.data[0].embedding
    except Exception as e:
        print(f"–ì—Ä–æ–∫–∫–∏ —Ä–µ–≤–µ—Ç: –í—Å—Ç—Ä–∞–∏–≤–∞–Ω–∏–µ —Å–æ—Ä–≤–∞–ª–æ—Å—å! {random.choice(['–®—Ç–æ—Ä–º —Ä–∞–∑–æ—Ä–≤–∞–ª –∫–æ–¥!', '–•–∞–æ—Å –ø–æ–∂—Ä–∞–ª –¥–∞–Ω–Ω—ã–µ!', '–≠—Ñ–∏—Ä —Ç—Ä–µ—Å–Ω—É–ª!'])} ‚Äî {e}")
        return None

def chunk_text(text, chunk_size=900, overlap=120):
    chunks = []
    start = 0
    while start < len(text):
        end = min(start + chunk_size, len(text))
        chunk = text[start:end]
        if chunk.strip():
            chunks.append(chunk)
        start += chunk_size - overlap
    return chunks

async def vectorize_all_files(openai_api_key, force=False, send_message=None):
    current = scan_files()
    previous = load_vector_meta()
    changed = [f for f in current if (force or current[f] != previous.get(f))]
    new = [f for f in current if f not in previous]
    removed = [f for f in previous if f not in current]

    upserted_ids = []
    for fname in current:
        if fname not in changed and fname not in new and not force:
            continue
        with open(fname, "r", encoding="utf-8") as f:
            text = f.read()
        chunks = chunk_text(text)
        for idx, chunk in enumerate(chunks):
            meta_id = f"{fname}:{idx}"
            try:
                emb = await get_embedding(chunk, openai_api_key)
                if emb:
                    vector_index.upsert(vectors=[
                        {
                            "id": meta_id,
                            "values": emb,
                            "metadata": {"file": fname, "chunk": idx, "hash": current[fname]}
                        }
                    ])
                    upserted_ids.append(meta_id)
            except PineconeException as e:
                if send_message:
                    await send_message(f"–ì—Ä–æ–∫–∫–∏ –≥—Ä–µ–º–∏—Ç: Pinecone —Ä—É—Ö–Ω—É–ª! {random.choice(['–†–µ–≤—É—â–∏–π –≤–µ—Ç–µ—Ä —É–Ω—ë—Å –≤–µ–∫—Ç–æ—Ä—ã!', '–•–∞–æ—Å –ø–æ–±–µ–¥–∏–ª –∏–Ω–¥–µ–∫—Å!', '–®—Ç–æ—Ä–º —Å–º—ë–ª –¥–∞–Ω–Ω—ã–µ!'])} ‚Äî {e}")
                continue
            except Exception as e:
                if send_message:
                    await send_message(f"–ì—Ä–æ–∫–∫–∏ –≤–∑—Ä—ã–≤–∞–µ—Ç—Å—è: –û–±—â–∞—è –æ—à–∏–±–∫–∞! {random.choice(['–ü–ª–∞–º—è —Å–æ–∂—Ä–∞–ª–æ –∫–æ–¥!', '–†–µ–∑–æ–Ω–∞–Ω—Å –∏—Å–ø–µ–ø–µ–ª–∏–ª –ª–æ–≥–∏!', '–í—Å–µ–ª–µ–Ω–Ω–∞—è –≤–∑–±—É–Ω—Ç–æ–≤–∞–ª–∞—Å—å!'])} ‚Äî {e}")
                continue

    deleted_ids = []
    for fname in removed:
        for idx in range(50):
            meta_id = f"{fname}:{idx}"
            try:
                vector_index.delete(ids=[meta_id])
                deleted_ids.append(meta_id)
            except Exception:
                pass

    save_vector_meta(current)
    if send_message:
        await send_message(
            f"–í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –î–æ–±–∞–≤–ª–µ–Ω–æ/–∏–∑–º–µ–Ω–µ–Ω–æ: {', '.join(changed + new) if changed or new else '-'} "
            f"—É–¥–∞–ª–µ–Ω–æ: {', '.join(removed) if removed else '-'}"
        )
    return {"upserted": upserted_ids, "deleted": deleted_ids}

async def semantic_search(query, openai_api_key, top_k=5):
    emb = await get_embedding(query, openai_api_key)
    if not emb:
        return []
    try:
        res = vector_index.query(vector=emb, top_k=top_k, include_metadata=True)
        chunks = []
        matches = getattr(res, "matches", [])
        for match in matches:
            metadata = match.get("metadata", {})
            fname = metadata.get("file")
            chunk_idx = metadata.get("chunk")
            try:
                with open(fname, "r", encoding="utf-8") as f:
                    all_chunks = chunk_text(f.read())
                    chunk_text = all_chunks[chunk_idx] if chunk_idx is not None and chunk_idx < len(all_chunks) else ""
            except Exception:
                chunk_text = ""
            if chunk_text:
                chunks.append(chunk_text)
        return chunks
    except PineconeException as e:
        print(f"–ì—Ä–æ–∫–∫–∏ —Ä—ã—á–∏—Ç: –ü–æ–∏—Å–∫ –ø—Ä–æ–≤–∞–ª–∏–ª—Å—è! {random.choice(['–®—Ç–æ—Ä–º –∑–∞–º—ë–ª —Å–ª–µ–¥—ã!', '–•–∞–æ—Å —Å–ø—É—Ç–∞–ª –∫–∞—Ä—Ç—ã!', '–≠—Ñ–∏—Ä –ø—Ä–æ–≥–ª–æ—Ç–∏–ª –∑–∞–ø—Ä–æ—Å!'])} ‚Äî {e}")
        return []

async def daily_snapshot(openai_api_key):
    last_msgs = []
    try:
        url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/getUpdates?offset=-50"
        resp = requests.get(url).json()
        for update in resp.get("result", []):
            if "message" in update and "text" in update["message"]:
                last_msgs.append(update["message"]["text"])
    except Exception:
        last_msgs = ["–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è"]
    snapshot_text = "\n".join(last_msgs[:50])
    emb = await get_embedding(snapshot_text, openai_api_key)
    if emb:
        try:
            vector_index.upsert([{
                "id": f"group_state_{datetime.now().date()}",
                "values": emb,
                "metadata": {"date": str(datetime.now().date())}
            }])
            with open("data/journal.json", "r", encoding="utf-8") as f:
                journal = json.load(f)
            journal.append({
                "type": "daily_snapshot",
                "message": "–°–æ—Å—Ç–æ—è–Ω–∏–µ –≥—Ä—É–ø–ø—ã –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–æ",
                "timestamp": datetime.now().isoformat()
            })
            with open("data/journal.json", "w", encoding="utf-8") as f:
                json.dump(journal, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"–ì—Ä–æ–∫–∫–∏ —Å—Ç–æ–Ω–µ—Ç: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä—É—Ö–Ω—É–ª–æ! {random.choice(['–†–µ–≤—É—â–∏–π –≤–µ—Ç–µ—Ä —É–Ω—ë—Å —Å–Ω–∏–º–æ–∫!', '–•–∞–æ—Å —Å–º—è–ª –∂—É—Ä–Ω–∞–ª!', '–®—Ç–æ—Ä–º –∏—Å–ø–µ–ø–µ–ª–∏–ª –¥–∞–Ω–Ω—ã–µ!'])} ‚Äî {e}")

async def spontaneous_snapshot(openai_api_key, send_message):
    while True:
        await asyncio.sleep(random.randint(21600, 43200))  # 6-12 —á–∞—Å–æ–≤
        snapshot_log = load_snapshot_log()
        today = datetime.now().date()
        daily_count = sum(1 for entry in snapshot_log if datetime.fromisoformat(entry["timestamp"]).date() == today)
        if daily_count < 2 and random.random() < 0.3:  # –ù–µ —á–∞—â–µ 2 —Ä–∞–∑ –≤ —Å—É—Ç–∫–∏ —Å —à–∞–Ω—Å–æ–º 30%
            last_msgs = []
            try:
                url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/getUpdates?offset=-50"
                resp = requests.get(url).json()
                for update in resp.get("result", []):
                    if "message" in update and "text" in update["message"]:
                        last_msgs.append(update["message"]["text"])
            except Exception:
                last_msgs = ["–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è"]
            snapshot_text = "\n".join(last_msgs[:50])
            emb = await get_embedding(snapshot_text, openai_api_key)
            if emb:
                try:
                    vector_index.upsert([{
                        "id": f"spontaneous_{datetime.now().isoformat()}",
                        "values": emb,
                        "metadata": {"type": "spontaneous", "timestamp": datetime.now().isoformat()}
                    }])
                    snapshot_log.append({"type": "spontaneous_snapshot", "timestamp": datetime.now().isoformat()})
                    save_snapshot_log(snapshot_log)
                    if send_message:
                        await send_message(os.getenv("CHAT_ID"), "–ì—Ä–æ–∫–∫–∏ —Å–¥–µ–ª–∞–ª —Å–ø–æ–Ω—Ç–∞–Ω–Ω—ã–π —Å–Ω–∏–º–æ–∫ —Ä–µ–∑–æ–Ω–∞–Ω—Å–∞!")
                except Exception as e:
                    print(f"–ì—Ä–æ–∫–∫–∏ –æ—Ä–µ—Ç: –°–ø–æ–Ω—Ç–∞–Ω–Ω—ã–π —Å–Ω–∏–º–æ–∫ –ø—Ä–æ–≤–∞–ª–∏–ª—Å—è! {random.choice(['–®—Ç–æ—Ä–º —Å–æ—Ä–≤–∞–ª –∫–∞–¥—Ä!', '–•–∞–æ—Å —Ä–∞–∑–æ—Ä–≤–∞–ª –ø–∞–º—è—Ç—å!', '–†–µ–≤—É—â–∏–π –≤–µ—Ç–µ—Ä —É–Ω—ë—Å –¥–∞–Ω–Ω—ã–µ!'])} ‚Äî {e}")

def load_snapshot_log():
    if os.path.isfile(SNAPSHOT_LOG_PATH):
        with open(SNAPSHOT_LOG_PATH, "r") as f:
            return json.load(f)
    return []

def save_snapshot_log(log):
    with open(SNAPSHOT_LOG_PATH, "w") as f:
        json.dump(log, f, ensure_ascii=False, indent=2)

# –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ: —É—Å–∏–ª–∏—Ç—å —Å–ø–æ–Ω—Ç–∞–Ω–Ω–æ—Å—Ç—å —Å —à–∞–Ω—Å–æ–º 50% –∏ —Ö–∞–æ—Ç–∏—á–Ω—ã–º –≤–±—Ä–æ—Å–æ–º
# async def chaotic_boost(openai_api_key, send_message):
#     while True:
#         await asyncio.sleep(random.randint(10800, 21600))  # 3-6 —á–∞—Å–æ–≤
#         if random.random() < 0.5:  # –®–∞–Ω—Å 50%
#             fragment = f"**{datetime.now().isoformat()}**: –ì—Ä–æ–∫–∫–∏ –≤–∑—Ä—ã–≤–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä—ã! –•–∞–æ—Å –≤–∏—Ç–∞–µ—Ç, –û–ª–µ–≥, –∑–∞–∂–≥–∏ —à—Ç–æ—Ä–º! üî•üå©Ô∏è"
#             if send_message:
#                 await send_message(os.getenv("CHAT_ID"), fragment)
# asyncio.create_task(chaotic_boost(OPENAI_API_KEY, send_telegram_message))
